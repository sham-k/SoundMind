# ğŸ§ SoundMind â€” AI Emotion Recognition from Voice

SoundMind is an AI-powered system that analyzes short voice clips and predicts the speakerâ€™s emotional state using deep learning and audio feature extraction.  
The project demonstrates machine learning, signal processing, and model deployment skills in a real-world, human-centered application.

---

## ğŸš€ Features

- ğŸ™ï¸ **Upload voice clips** (.wav) through a simple Streamlit UI  
- ğŸ§  **Emotion classification** using MFCC audio features  
- ğŸ¤– **Deep learning model** (Keras + TensorFlow)  
- ğŸ“ˆ **Training pipeline** for preprocessing and feature extraction  
- ğŸ” **Supports all 8 RAVDESS emotions:**  
  - Neutral  
  - Calm  
  - Happy  
  - Sad  
  - Angry  
  - Fearful  
  - Disgust  
  - Surprised  

---

## ğŸ—‚ Project Structure

SoundMind/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py           # Streamlit UI
â”‚   â”œâ”€â”€ preprocess.py     # Audio â†’ MFCC feature extraction
â”‚   â””â”€â”€ utils.py          # Model loading & prediction helpers
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # RAVDESS audio dataset (ignored by Git)
â”‚   â””â”€â”€ processed/        # Generated features.csv
â”‚
â”œâ”€â”€ models/               # Saved emotion_model.h5 (ignored by Git)
â”‚
â”œâ”€â”€ notebooks/            # Future experimentation notebooks
â”‚
â”œâ”€â”€ train.py              # Model training script
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## ğŸ“¦ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/sham-k/SoundMind.git
cd SoundMind
```
### 2ï¸âƒ£ Create & activate virtual environment (Python 3.11)
```bash
python3.11 -m venv .venv
source .venv/bin/activate
```
### 3ï¸âƒ£  Install dependencies
```bash
pip install --upgrade pip setuptools wheel
pip install -r requirements.txt || pip install tensorflow-macos
```
## Dataset (RAVDESS)

SoundMind uses the RAVDESS Speech Audio Dataset:
Download: https://zenodo.org/record/1188976

Required ZIP file:
Audio_Speech_Actors_01-24.zip

Place it here:
```bash
SoundMind/data/raw/
```
## ğŸ§  Preprocessing (Audio â†’ MFCC)
Convert .wav audio files to MFCC feature vectors:
```bash
python app/preprocess.py
```
Generates:
```bash
data/processed/features.csv
```
Each row contains:
* 40 MFCC audio features
* Emotion label

## ğŸ‹ğŸ¾â€â™‚ï¸ Train the Model
Train your deep learning emotion classifier:
```bash
python train.py
```
Outputs:
```bash
models/emotion_model.h5
```
Model Architecture:
* Dense (256) + Dropout
* Dense (128) + Dropout
* Softmax output (8 classes

##  Run the Streamlit App
Start the web UI:
```bash
streamlit run app/main.py
```
 Then visit
  http://localhost:8501
Upload a .wav file to get:
*  Predicted emotion
*  Confidence score

  ## Tech Stack
  * Python
  * TensorFlow / TensorFlow-macOS
  * Librosa for audio processing
  * NumPy / Pandas
  * Streamlit for UI

Machine Learning Concepts:
* MFCC feature extraction
* Deep neural networks
* Audio signal processing
* Emotion inference

## Roadmap

* Real-time microphone emotion recognition
*  Probability bar chart visualization
*  Upgrade to Wav2Vec2, HuBERT, or YAMNet
*  Multi-language emotion detection
*   Build a React / React Native UI
*    Deploy on Hugging Face Spaces or Render

